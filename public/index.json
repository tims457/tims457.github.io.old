
[{"content":"I\u0026rsquo;m an aerospace engineer living in Colorado. I graduated from the US Military Academy at West Point before going on to serve as an aviation officer and UH-60M Blackhawk pilot. I left the military in 2018 and attended graduate school at the University of Colorado Boulder graduating with an MS in Aerospace Engineering. Outside of engineering, I enjoy hiking, trail running (including the occasional ultramarathon), biking, and climbing.\nContact me on Twitter.\nOther Stuff # Interesting research papers and blog posts ","date":"10 March 2024","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"10 March 2024","externalUrl":null,"permalink":"/archive/","section":"","summary":"","title":"","type":"archive"},{"content":"","date":"10 March 2024","externalUrl":null,"permalink":"/tags/learning/","section":"Tags","summary":"","title":"Learning","type":"tags"},{"content":"Some good discussions on learning and writing worth sharing.\nHow to Understand Things - On habits to increase understanding and intelligence.\nLearning how to Learn - Tactics and techniques for learning more effectively and making things stick.\nLearning by Writing - A method for organizing learning through writing rather than reading by iteratively forming, critiquing, and reforming your view. Reminds me of John Boyd\u0026rsquo;s Destruction and Creation.\nThe Craft of Writing Effectively - Most of the resources above are about learning and writing to learn, but this probably isn\u0026rsquo;t the way you want to write professionally. In this lecture, Larry McEnerney discusses the difference between writing professionally and writing to think. He emphasizes the goal of professional writing is not just to convey your ideas, but to change the reader\u0026rsquo;s ideas about a subject.\n","date":"10 March 2024","externalUrl":null,"permalink":"/archive/2024-03-10-resources-on-learning-and-writing/","section":"","summary":"","title":"Resources on learning and writing","type":"archive"},{"content":"","date":"10 March 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"10 March 2024","externalUrl":null,"permalink":"/tags/writing/","section":"Tags","summary":"","title":"Writing","type":"tags"},{"content":"","date":"9 December 2023","externalUrl":null,"permalink":"/tags/dissipative-adaptation/","section":"Tags","summary":"","title":"Dissipative Adaptation","type":"tags"},{"content":"","date":"9 December 2023","externalUrl":null,"permalink":"/tags/life/","section":"Tags","summary":"","title":"Life","type":"tags"},{"content":" Concepts # Macroscopic coarse-graining - many microscopic ways of arranging matter that have the same macroscopic (coarse) features, indistinguishable when considering the whole\nEntropy- $S$, number of microscopic ways a given coarse grained outcome can be achieved.\nBoltzmann Distribution - The probability that a system is in a given microstate $p_i$ is proportional to its temperature $T$ and energy $E$.\n$$p_i \\propto \\exp(-\\frac{E}{k_BT})$$\nwhere $k_B$ is the Boltzmann constant. High energy states are exponentially less likely to be visited than lower, but the exponential gets shallower as temperature, $T$, increases.\nFree Energy - $F$, change in free energy is the maximum amount of work that the system can perform at constant temperature. Corresponds to the Boltzmann probability of a coarse-grained state. Higher probability corresponds to lower free energy. Lower free energy is achieved either through lower energy and/or higher entropy. $$F = E - T S$$\nCrooks Equation (Crooks fluctuation theorem) - The probability of a forward-in-time trajectory, $P[x(t)]$ to the reverse trajectory $\\tilde{P}[\\tilde{x}(t)]$ is exponentially more likely given that the forward-in-time trajectory produces entropy.\n$$\\frac{P[x(t)]}{\\tilde{P}[\\tilde{x}(t)]}=e^{\\sigma[x(t)]}$$\nOnce heat diffuses, it is very unlikely to randomly return. Systems that are directional release heat, but if their energy is not decreasing, and total energy is conserved, another external source must be injecting energy.\nNon-equilibrium Steady State - Stable system not at thermal equilibrium. They do not appear the same under time-reversal and contrast with systems at thermal equilibrium. Must have a continuous external drive of energy to remain in this state.\nTime reversal symmetry breaking - Replication and other behaviors need to achieve a state which is not at lowest energy but is also stable. According to Crooks equation, staying in a state which is not at thermal equilibrium through random fluctuations is unlikely. Being in this state breaks the symmetry of forward/backward trajectories being equally likely. External energy or force inputs are necessary for symmetry breaking to occur and keep the system in a state it would not inhabit through random fluctuations\nLife needs to be able to resist environmental thermal fluctuations leading to increased entropy without being frozen in a rigid configuration. A crystal-like low energy state has no flexibility to reorganize itself in response to the environment. In order to be both flexible and resistant, a sustained energy input is required.\nSubjecting inanimate matter or simulations to an external drive can result in the spontaneous emergence of structure.\nDissipative Adaptation\nThe self-organization of a system based on interaction with its environment. This process is affected by the structure of the system, but the energy input can also create a re-arrangement of the system creating new relationships between the system and the environment. The system may adapt into a configuration which is good at absorbing energy or dissipating excess energy. {:width=\u0026ldquo;95%\u0026rdquo;} Energy barrier transition, (reproduced from [2]) {:.image-caption}\nGiven an external drive, certain configurations of the system may be better than others at absorbing work. If the system is configured in such a way that the energy from the external drive enables the transition of energy barriers followed by the dissipation of energy, then the system will not be able to transition back. Over time the system will adopt states that allowed this process to occur appearing to have self-organized based on its environment. If the environment changes, the system can reconfigure yet again. References # [1] England, Jeremy. Every Life Is on Fire: How Thermodynamics Explains the Origins of Living Things. 2020. [2] England, Jeremy L. “Dissipative Adaptation in Driven Self-Assembly.” Nature Nanotechnology, November 1, 2015. https://doi.org/10.1038/nnano.2015.250. ","date":"9 December 2023","externalUrl":null,"permalink":"/archive/2023-12-09-notes-on-every-life-is-on-fire/","section":"","summary":"","title":"Notes on Every Life is on Fire","type":"archive"},{"content":"","date":"9 December 2023","externalUrl":null,"permalink":"/tags/statistical-mechanics/","section":"Tags","summary":"","title":"Statistical Mechanics","type":"tags"},{"content":"","date":"9 December 2023","externalUrl":null,"permalink":"/tags/thermodynamics/","section":"Tags","summary":"","title":"Thermodynamics","type":"tags"},{"content":"","date":"14 February 2023","externalUrl":null,"permalink":"/tags/decision-making/","section":"Tags","summary":"","title":"Decision Making","type":"tags"},{"content":"","date":"14 February 2023","externalUrl":null,"permalink":"/tags/julia/","section":"Tags","summary":"","title":"Julia","type":"tags"},{"content":"","date":"14 February 2023","externalUrl":null,"permalink":"/tags/monte-carlo-tree-search/","section":"Tags","summary":"","title":"Monte Carlo Tree Search","type":"tags"},{"content":" Monte Carlo Tree Search (MCTS) is an algorithm used in decision-making and search problems. The algorithm builds a search tree of possible moves and outcomes, exploring the tree by simulating a number of games to determine the best moves. MCTS balances exploration of unexplored nodes and exploitation of nodes that have shown promise in the past. The algorithm selects the best move to make from the current game state based on the statistics collected during the simulation phase.\nAlgorithm # Initialize POMDP problem Root node Hyperparameters $d$ = search depth $m$ = search simulations before choosing best action $c$ = exploration constant $U$ = value function estimate method, rollout simulator For $m$ simulations, do:\nSelection: If first simulation: Expand root node creating child nodes for all possible actions (or modification). Return value estimate from root node using rollout If not first simulation: Select best action according to UCB metric $Q(s, a)+c \\sqrt{\\frac{\\log N(s)}{N(s, a)}}$ Expansion: If node has no children and is not terminal expand it. Create next state, $s\u0026rsquo;$ using transition distribution and chosen action, creating new unexplored nodes for each possible action from $s\u0026rsquo;$. The transition distribution won\u0026rsquo;t necessarily yield the same $s\u0026rsquo;$ next time this action is taken from $s$. If node has children and not at max depth, return to Selection Rollout: When max depth is reached, get value estimate using rollout and policy. This is the leaf node. Backprop: Recursively propagate value estimate at leaf node backwards through tree, updating value estimate $Q$ at each parent using current reward + discounted future reward. Code # Based on [1] with additional explanation.\nmutable struct MCTS P # problem MDP or POMDP N # visit counts, dictionary over (s, a) pairs Q # value estimates, dictionary over (s, a) pairs d # depth, search horizon m # number of simulations before choosing an action c # exploration constant U # value function estimate, rollout simulator or other method end function (π::MCTS)(s) for k in 1:π.m simulate!(π, s) end # return action with highest value estimate from # the set of actions available in state s return argmax(a-\u0026gt;π.Q[s,a], actions(π.P, s)) end bonus(Na, Ns) = Na == function simulate!(π::MCTS, s, d=π.d) # if at max depth, return value estimate for state s if d \u0026lt;= 0 return π.U(s) end # get problem, visit counts, value estimates, exploration constant P, N, Q, c = π.P, π.N, π.Q, π.c # get actions, transition function, discount factor A, TR, γ = actions(P, s), transition(P, s), discount(P) # if node has not been explored, expand it, creating a new node for each action # (i.e. add it to the tree) # initializing visit counts and value estimates to 0 for all actions # (another method could be used to set the initial value estimate) if !haskey(N, (s, first(A))) for a in A N[(s, a)] = 0 Q[(s, a)] = 0.0 end # return value estimate for this state through rollout return π.U(s) end # if node has been expanded, select action according to UCB1 formula a = explore(π, s) # transition to next state and get reward sp, r = TR(a) # set value to reward plus discounted value estimate for next state q = r + γ * simulate!(π, sp, d-1) # update visit count and value estimate for this state-action pair N[(s, a)] += 1 Q[(s, a)] += (q - Q[(s, a)]) / N[(s, a)] return q end # unexplored actions have infinite bonus bonus(Na, Ns) = Na == 0 ? Inf : sqrt(log(Ns) / Na) function explore(π::MCTS, s) A, N, Q, c = actions(π.P, s), π.N, π.Q, π.c # sum over all actions for the number of visits to the node Ns = sum(N[(s, a)] for a in A) # return action with highest value estimate plus bonus * exploration constant return argmax(a-\u0026gt;Q[(s, a)] + c * bonus(N[(s, a)], Ns), A) end POMDPs.transition(P, s) = (a)-\u0026gt; @gen(:sp, :r)(P, s, a) function U(P, policy, s) # rollout simulator # simulate policy from current node returning reward sim = RolloutSimulator(max_steps=10) r = simulate(sim, P, policy, s) return r end Modifications # (Double) Progressive Widening Limit the number of actions considered from state $s$ Limit the number of states resulting from action $a$ Other rollout methods References # [1] M. J. Kochenderfer, T. A. Wheeler, and K. H. Wray, Algorithms for decision making. Cambridge, Massachusetts: The MIT Press, 2022.\n","date":"14 February 2023","externalUrl":null,"permalink":"/archive/monte_carlo_tree_search/","section":"","summary":"","title":"Monte Carlo Tree Search","type":"archive"},{"content":"","date":"14 February 2023","externalUrl":null,"permalink":"/tags/uncertainty/","section":"Tags","summary":"","title":"Uncertainty","type":"tags"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"I love to read, and try to get through a couple dozen books a year. I didn\u0026rsquo;t always keep a list so there are plenty missing. I\u0026rsquo;ve also been going back and adding a meaningful quote or two.\nSome favorites # Antifragile Boyd Blindsight Complexity a Guided Tour Exhalation Finite and Infinite Games Lessons of History Nature smiles at the union of freedom and equality in our utopias. For freedom and equality are sworn and everlasting enemies, and when one prevails the other dies.\nA Man for all Markets We didn’t ask, Is the market efficient? but rather, In what ways and to what extent is the market inefficient? and How can we exploit this?\nMan\u0026rsquo;s Search for Meaning Meditations The mind adapts and converts to its own purposes the obstacle to our acting. The impediment to action advances action. What stands in the way becomes the way.\nThe Most Important Thing The Moves that Matter Similarly, if you ask a Grandmaster about the chessboard in their head, you will find it doesn’t have a size or a shape or a colour. What we have is an implicit sense of the rules of the game, the relationships between the pieces and the prevailing strategic purposes.\nThe Obstacle is the Way Outliers Sapiens Seveneves Siddhartha Stories of Your Life and Others Surely You\u0026rsquo;re Joking Mr. Feynman Thinking in Bets The Three-Body Problem Trilogy Zero to One Somewhat chronologically # Reflections on Net Assessment\nFoundry\nConflict\nReap3r\nNet Assessment and Military Strategy\nThe Maniac\nMastery\n2034\nEvery Life Is on Fire: How Thermodynamics Explains the Origins of Living Things\nThe Jungle Grows back\nThe Theoretical Minimum: Quantum Mechanics\nChaos Kings\nThe Art of Learning\nBlindsight\nThe Theoretical Minimum: Classical Mechanics\nThe Player of Games\nThe Last Warrior: Andrew Marshall and the Shaping of Modern American Defense Strategy\nWhy Greatness Cannot Be Planned\nThe problem is that the stepping stone does not resemble the final product.\nScience, Strategy and War: The Strategic Theory of John Boyd\nThe dominant and overarching theme in Boyd’s work is not the narrow interpretation of rapid OODA looping, or “decision superiority”, but rather the ability to adapt to the unfolding, multidimensional events, which occur at different time scales.\nThe Mind of War\nWhat Boyd is all about is a way of thinking and the creation of organizations and organisms that are adaptive and capable of rapidity, variety, harmony, and initiative. Only in this way can they hope to survive and prosper in the face of complex change and uncertainty.\nThe Kill Chain\nIn reality, true military innovation is less about technology than about operational and organizational transformation. Indeed, history is replete with examples of military rivals that had the same technologies, and what set them apart is how they used them and organized themselves differently.\nOur focus must be on building and buying integrated networks of kill chains, not individual platforms and systems. We need to buy outcomes, not things.\nMarket Tremors\nIf we had to write a rough prescription for adjusting risk estimates in the presence of a Dominant Agent, it would be guided by the following questions. Who are the main players in a given market or asset class? How big are they, in terms of balance sheet size, ownership or percentage of volume traded? What is their typical behavior? Do they trade in the direction of a price move, trade against it or do they display chameleon-like behavior based on prevailing market conditions? How much will they be forced to trade, given a sufficiently large price shock in a specific direction? What is the likely price impact of forced rebalancing of fixed size?\nRed Blooded Risk\nTaking less risk than is optimal is not safer; it just locks in a worse outcome. In competitive fields, doing less than the best often means failing completely. Taking more risk than is optimal also results in a worse outcome, and often leads to complete disaster.\nBall Lightning\nThe Silk Roads\nPrice Wars\nBall Lightning\nDraft No 4\nFinite and Infinite Games\nBoyd\nExhalation\nworking backwards\nEarth unaware\nHow to take smart notes\nGenome\nCryptonomicon\nComplexity a Guided Tour\nThinking in Systems\nThinking in Bets\nArrival\nThe Man Who Solved the Market\nGood omens\nDark Forest\nSuperforecasting\nTraining for the Uphill Athlete\nSeventh Sense\nWay of the Peaceful Warrior\nLeft of Boom\nEmotional Intelligence (Goleman)\nLeonardo da Vinci\nHomo Deus\nInfluence\nThe Rise of Money\nOutliers\nDavid and Goliath\nTipping Point\n12 Rules for Life\nStealing fire\nThe Three Body Problem\nZero to One\nThe First Tycoon\nFirst Man\nIron Gold - Red Rising 4\nSmall Puddles\nIrrational Exuberance- Jan\nSurely You’re Joking Mr Feynmann\nThe Subtle Art of Not Giving a Fuck\nSeveneves\nSeeking Wisdom\nMan for All Markets\nDouble Government\nFooled by Randomness\nThe Undoing Project\nThe Afghan Campaign\nThe Most Important Thing\nRisk means more things can happen than will happen.\nThe process of intelligently building a portfolio consists of buying the best investments, making room for them by selling lesser ones, and staying clear of the worst. The raw materials for the process consist of (a) a list of potential investments, (b) estimates of their intrinsic value, (c) a sense for how their prices compare with their intrinsic value, and (d) an understanding of the risks involved in each, and of the effect their inclusion would have on the portfolio being assembled.\nDestined for War\n33 Strategies of War\nIn strategy all of life is a game that you are playing.\nThe Effective Executive\nThe effective executive is concerned first with understanding. Only then does he even think about who is right and who is wrong.\nI have never encountered an executive who remains effective while tackling more than two tasks at a time.\nGrokking Algorithms\nLessons of History\nPrinciples (Dalio)\nCode\nFoundation\nArtemis\nTribe\nLetters from a Stoic\nMeditations\nAntifragile\nThe War of Art\nThe paradox seems to be, as Socrates demonstrated long ago, that the truly free individual is free only to the extent of his own self-mastery. While those who will not govern themselves are condemned to find masters to govern over them.\nMan\u0026rsquo;s Search for Meaning\nIntelligent Investor\nRandom Walk down Wall Street\nHow to not be wrong\nGame of Thrones\nEgo is the Enemy\nSapiens\nFailure is not an Option\nElon Musk\nThe Obstacle is the Way\nWhat we can do is limit and expand our perspective to whatever will keep us calmest and most ready for the task at hand. Think of it as selective editing—not to deceive others, but to properly orient ourselves.\n","externalUrl":null,"permalink":"/books/","section":"","summary":"","title":"Books","type":"page"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"The EscaPADE Mission Design\nJ. S. Parker, A. Koehler, C. Ott, and T. M. Sullivan.\nAmerican Astronautical Society (AAS) Guidance, Navigation \u0026amp; Control (GNC) Conference, 2022.\nNeural Networks for Onboard Maneuver Design\nN. Ré, T. M. Sullivan, M. D. Popplewell, K. S. Roerig, C. Michael, T. Hanff, T. Presser.\nInternational Astronautical Congress (IAC), 2022.\n","externalUrl":null,"permalink":"/research/","section":"","summary":"","title":"Research","type":"page"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]